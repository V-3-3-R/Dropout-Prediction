# ğŸ“ JEE Dropout Prediction: Machine Learning Models for Identifying At-Risk Students

**Language:** Python  
**Libraries:** scikit-learn, pandas, seaborn, matplotlib  
**License:** MIT  

---

## ğŸ§  Overview

This project develops **machine learning models** to predict student dropout risks in **Joint Entrance Examination (JEE)** preparation programs after Class 12.  
Using a **simulated dataset**, we train and compare three classifiers:

- **Logistic Regression**
- **Random Forest**
- **Gradient Boosting**

The goal is to identify key factors contributing to dropouts â€” such as **academic scores**, **study habits**, **family background**, and **mental health indicators** â€” and provide educators and institutes with an **early warning system** to support at-risk students.

---

## âœ¨ Key Features

- **Data Preprocessing:** Handles categorical encoding (one-hot) and numerical scaling.  
- **Model Comparison:** Evaluates accuracy, precision, recall, F1-score, and confusion matrices.  
- **Feature Importance:** Analyzes top predictors using tree-based models.  
- **Visualizations:** Bar charts, box plots, stacked bars, and heatmaps for insights.  
- **Reproducible:** Runs easily in **Jupyter Notebook** or as a **Python script**.

---

## ğŸ—‚ï¸ Dataset

The project uses the **`JEE_Dropout_After_Class_12.csv`** dataset â€” a simulated collection of **5,000 student records** with **15 features**.  
It includes:

- **Academic metrics:** JEE scores, Class 12 percentage  
- **Socioeconomic factors:** Family income, parental education  
- **Behavioral indicators:** Daily study hours, mental health issues  

ğŸ¯ **Target variable:** `dropout`  
- `1` â†’ Dropped out  
- `0` â†’ Continued  

---

### ğŸ“¥ Downloading the Dataset

1. Visit the **[Kaggle Dataset Page](https://www.kaggle.com/)**.  
2. Sign in or create a free account.  
3. Click **Download** (~377 KB ZIP).  
4. Extract and place `JEE_Dropout_After_Class_12.csv` in your project root directory.

> Note: The dataset is synthetic but realistic, designed to mimic real-world JEE preparation scenarios in India.

---

## âš™ï¸ Installation

Clone the repository:

```bash
git clone https://github.com/yourusername/jee-dropout-prediction.git
cd jee-dropout-prediction
```

# Create and activate a virtual environment (recommended):
```bash
python -m venv venv
```
# On macOS/Linux
```bash
source venv/bin/activate
```
# On Windows
```bash
venv\Scripts\activate
```
# Install dependencies:
```bash
pip install -r requirements.txt
```
# Or install manually:
```bash
pip install pandas scikit-learn seaborn matplotlib numpy
```

# Requirements.txt
- pandas>=1.5.0
- scikit-learn>=1.2.0
- seaborn>=0.12.0
- matplotlib>=3.6.0
- numpy>=1.24.0

# ğŸš€ Usage
â–¶ï¸ Running the Python Script
Execute the main script to load data, train models, evaluate performance, and generate plots:
python bda_rp.py

This will:
- Display data overview and splits
- Train and compare the three models
- Print performance metrics (e.g., F1-scores)
- Save visualizations as .png files (e.g., dropout_count_bar_chart.png)

# ğŸ’» Running the Jupyter Notebook
For interactive exploration:
- ```bash
  jupyter notebook
  ```
- Then open DROPOUT2.ipynb and run all cells.

# ğŸ“Š Expected Output
| Model               | Accuracy | Precision | Recall | F1-Score |
| ------------------- | -------- | --------- | ------ | -------- |
| Logistic Regression | ~0.82    | ~0.80     | ~0.78  | ~0.79    |
| Random Forest       | ~0.88    | ~0.87     | ~0.85  | ~0.86    |
| Gradient Boosting   | ~0.90    | ~0.89     | ~0.88  | ~0.88    |

Metrics are based on an 80/20 stratified train-test split (random_state=42).
Dropout ratio â‰ˆ 0.25 in both sets.

# ğŸŒŸ Top 5 Features (from Gradient Boosting)
| Rank | Feature Name               | Importance |
| ---- | -------------------------- | ---------- |
| 1ï¸âƒ£  | `mock_test_score_avg`      | 0.25       |
| 2ï¸âƒ£  | `daily_study_hours`        | 0.18       |
| 3ï¸âƒ£  | `mental_health_issues_Yes` | 0.12       |
| 4ï¸âƒ£  | `jee_advanced_score`       | 0.10       |
| 5ï¸âƒ£  | `family_income_Low`        | 0.08       |

# ğŸ¤ Contributing
Contributions are welcome!
To contribute:
# 1. Fork the repo
# 2. Create a feature branch
git checkout -b feature/amazing-feature
# 3. Commit your changes
git commit -m 'Add amazing feature'
# 4. Push to the branch
git push origin feature/amazing-feature
Then, open a Pull Request ğŸš€
Report any issues via GitHub Issues.

ğŸ™Œ Acknowledgments

Dataset: Kaggle â€” Simulated Dataset: JEE Dropout After Class 12 by Jayaantanaath.
Tools: scikit-learn, pandas, seaborn, matplotlib.
Purpose: To promote data-driven educational interventions and reduce dropout rates in competitive exam preparation.

# ğŸ’¡ Built with â¤ï¸ for educational data science research and student success prediction.
